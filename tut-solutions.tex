\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, amsfonts, amsthm, mathtools,mathrsfs}
\usepackage{thmtools}
\usepackage[utf8]{inputenc}
\usepackage[inline]{enumitem}
\usepackage[colorlinks=true]{hyperref}
\usepackage{tikz}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{arrows.meta}
\usepackage{witharrows}
\usepackage{datetime2}

\setlength\parindent{0pt}
\usepackage{parskip}

\usepackage[framemethod=tikz]{mdframed}
\mdfdefinestyle{theoremstyle}{%
	% linecolor=gray,linewidth=1pt,%
	% frametitlerule=true,%
	% frametitlebackgroundcolor=blue!20,
	% backgroundcolor=  gray!20,	
	bottomline=false, topline=false, rightline=false, leftline=true,
	innerlinewidth=0.7pt, outerlinewidth=0.7pt, middlelinewidth=2pt, middlelinecolor=white, %
	innerleftmargin=6pt,
	innertopmargin=-1pt,
	% innerbottommargin=-0.5pt,
}
\mdtheorem[style=theoremstyle]{defn}[thm]{Definition}
\mdtheorem[style=theoremstyle]{thm}{Theorem}

\usepackage{xpatch}
\newcommand{\thmautorefname}{Theorem}
\makeatletter
\xpatchcmd{\thm}{\refstepcounter}{\NR@gettitle{#1}\refstepcounter}{}{}
\makeatother

\theoremstyle{definition}
% \newtheorem{thm}{Theorem}
% \numberwithin{thm}{section}
% \newtheorem{lem}[thm]{Lemma}
% \newtheorem{defn}[thm]{Definition}
% \newtheorem{prop}[thm]{Proposition}
% \newtheorem{cor}[thm]{Corollary}
% \newtheorem{ex}{Example}


\let\emptyset\varnothing

\pagestyle{plain}

\usepackage{titlesec}
\titleformat{\section}[block]{\sffamily\Large\filcenter\bfseries}{\S\thesection.}{0.25cm}{\Large}
\titleformat{\subsection}[block]{\large\bfseries\sffamily}{\S\S\thesubsection.}{0.2cm}{\large}

\usepackage[a4paper]{geometry}
\usepackage{lipsum}

\usepackage{cleveref}
\crefname{thm}{Theorem}{Theorems}
\crefname{lem}{Lemma}{Lemmas}
\crefname{defn}{Definition}{Definitions}
\crefname{prop}{Proposition}{Propositions}
\crefname{cor}{Corollary}{Corollaries}
\crefname{equation}{}{}

\usepackage{mdframed}
\newenvironment{blockquote}
{\begin{mdframed}[skipabove=0pt, skipbelow=0pt, innertopmargin=4pt, innerbottommargin=4pt, bottomline=false,topline=false,rightline=false, linewidth=2pt]}
{\end{mdframed}}
\newenvironment{soln}{\begin{proof}[Solution]}{\end{proof}}

\usepackage{fancyhdr}
\setlength{\headheight}{15.2pt}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\sffamily{\S\textbf{\nouppercase{\leftmark}}}}
\fancyhead[R]{\sffamily{\thepage}}
\definecolor{myupdatecolor}{RGB}{0, 0, 255}

% \usepackage{xcolor}
% \definecolor{mybgcolor}{RGB}{50, 50, 50} %46, 51, 63
% \usepackage{pagecolor}
% \pagecolor{mybgcolor}
% \color{white}
% \mdfsetup{backgroundcolor=mybgcolor, fontcolor=white}
% \definecolor{myupdatecolor}{RGB}{0, 255, 0}

\renewcommand{\familydefault}{\sfdefault}

\title{MA 205: Complex Analysis\\\large{Tutorial Solutions}}
\author{Aryaman Maithani\\\url{https://aryamanmaithani.github.io/tuts/ma-205}}
\date{Autumn Semester 2020-21\\~\\Last update: \DTMnow}

\begin{document}
\tikzset{lab dis/.store in=\LabDis,
  lab dis=0.4,
  ->-/.style args={at #1 with label #2}{decoration={
    markings,
    mark=at position #1 with {\arrow{>}; \node at (0,\LabDis) {#2};}},postaction={decorate}},
  -<-/.style args={at #1 with label #2}{decoration={
    markings,
    mark=at position #1 with {\arrow{<}; \node at (0,\LabDis)
    {#2};}},postaction={decorate}},
  -*-/.style args={at #1 with label #2}{decoration={
    markings,
    mark=at position #1 with {{\fill (0,0) circle (1.5pt);} \node at (0,\LabDis)
    {#2};}},postaction={decorate}},
  }
\maketitle
\tableofcontents
\newpage
\setcounter{section}{-1}
\section{Notations}
\begin{enumerate}
	\item Given $z \in \mathbb{C},$ $\Re z$ and $\Im z$ will denote the real and imaginary parts of $z,$ respectively.
	\item Given $z \in \mathbb{C},$ $\bar{z}$ will denote the complex conjugate of $z.$
	\item Given $z \in \mathbb{C},$ $\left|z\right|$ will denote the modulus of $z,$ defined as $\sqrt{z\bar{z}}$ or $\sqrt{\left(\Re z\right)^2 + \left(\Im z\right)^2}.$
	\item Given $z_0 \in \mathbb{C}$ and $\delta > 0,$
	\begin{equation*} 
		B_\delta(z_0) \vcentcolon= \{z \in \mathbb{C} : |z - z_0| < \delta\}.
	\end{equation*}
	\item $\mathbb{C}^\times \vcentcolon= \mathbb{C}\setminus\{0\},$ the set of nonzero complex numbers.
\end{enumerate}
\newpage\section{Tutorial 1}
\begin{center}
	25th August, 2020
\end{center}
\textbf{Notation:} The set $\mathbb{C}[x]$ is the set of all polynomials (with indeterminate $x$) with complex coefficients. Similarly, $\mathbb{R}[x]$ is defined.
\begin{enumerate}
	\item  Show that complex polynomial of degree $n$ has exactly $n$ roots. (Assuming fundamental theorem of algebra.)\\
	Remark (my own): The above is counting the roots \emph{with} multiplicity. That is, if $f(z) = (z - \iota)^2(z - 2),$ then $\iota$ is counted twice and $2$ once.
	\begin{soln}
		Let $f(x) \in \mathbb{C}[x]$ be a polynomial of degree $n.$
		We prove this via induction on $n.$\\
		$n = 1.$ Then, $f(x) = a_0 + a_1x$ for some $a_0, a_1 \in \mathbb{C}$ and $a_1 \neq 0.$\\
		Note that
		\begin{align*} 
			f(x) &= 0\\
			\iff a_0 + a_1x &= 0\\
			\iff a_1x &= -a_0\\
			\iff x &= -\dfrac{a_0}{a_1}.
		\end{align*}
		Thus, $f(x)$ has exactly $1$ root.\\~\\
		Let us assume that whenever $g(x) \in \mathbb{C}[x]$ is a polynomial of degree $n,$ then $g(x)$ has exactly $n$ roots. (Counted with multiplicity.)\\
		Let $f(x) \in \mathbb{C}[x]$ be a polynomial of degree $n + 1.$ By FTA, there exists a root $x_0 \in \mathbb{C}.$ Thus, we can write
		\begin{equation*} 
			f(x) = (x - x_0)g(x)
		\end{equation*}
		for some polynomial $g(x) \in \mathbb{C}[x]$ of degree $n.$ Moreover, note that 
		\begin{equation*} 
			f(x) = 0 \iff x = x_0 \text{ or } g(x) = 0.
		\end{equation*}
		By induction, the latter is possible for exactly $n$ values of $x.$ Thus, in total, $f(x)$ has $n + 1$ roots. (Both counts are with multiplicity.)
	\end{soln}
	%
	%
	%
	\item Show that a real polynomial that is irreducible has degree at most two. i.e., if
	\begin{equation*} 
		f(x) = a_0 + a_1x + \cdots + a_nx^n, \quad a_i \in \mathbb{R}
	\end{equation*}
	then there are non-constant real polynomials $g$ and $h$ such that $f(x) = g(x)h(x)$ if $n \ge 3.$\\
	Remark (my own): $a_n \neq 0,$ of course.
	\begin{soln}
		Let $f(x) \in \mathbb{R}[x]$ with degree $\ge 3$ as above.\\
		If $f(x)$ has a real root, then we are done by factoring as in the earlier question.\\~\\
		Thus, let us assume that $f(x) = 0$ has no real solution.\\
		We may view $f(x) \in \mathbb{C}[x].$ Now, using FTA, we know that $f(x)$ has a complex root $x_0 \in \mathbb{C}.$ By assumption, we must have $x_0 \notin \mathbb{R}$ or that $x_0 \neq \overline{x_0}.$ \\
		\begin{blockquote}
			\textbf{Claim.} $f(\overline{x_0}) = 0.$
			\begin{proof} 
				Note that

				\[\begin{WithArrows}[displaystyle]
			    f(\overline{x_0}) &= a_0 + a_1\overline{x_0} + \cdots + a_n(\overline{x_0})^n \Arrow{$\because \overline{z^n} = \bar{z}^n$}\\
					&= a_0 + a_1\overline{x_0} + \cdots + a_n\overline{x_0^n} \Arrow{$\because a_i \in \mathbb{R}$ and so, $a_i = \overline{a_i}$}\\
					&= \overline{a_0} + \overline{a_1}\;\overline{x_0} + \cdots + \overline{a_n}\overline{x_0^n} \Arrow{$\overline{z_1z_2 + z_3} = \overline{z_1}\;\overline{z_2} + \overline{z_3}$}\\
					&= \overline{f(x_0)}\\
					&= \bar{0}\\
					&= 0
			  \end{WithArrows}\]
			\end{proof}
		\end{blockquote}
		Define $g(x) = (x - x_0)(x - \overline{x_0}).$ A priori, this is a polynomial in $\mathbb{C}[x].$ However, upon multiplication, we see that the polynomial is actually an element of $\mathbb{R}[x].$ Indeed, we have
		\begin{equation*} 
			(x - x_0)(x - \overline{x_0}) = (x^2 - (2\Re x_0)x + |x_0|^2) \in \mathbb{R}[x].	
		\end{equation*}
		By our claim, we see that $g(x)$ divides $f(x)$ in $\mathbb{C}[x].$ (Since $x_0$ and $\overline{x_0}$ are distinct, the polynomials $x - x_0$ and $x - \overline{x_0}$ are ``coprime'' and thus, if they individually divide $f(x),$ then their product must too.) \\
		Thus,
		\begin{equation*} 
			f(x) = g(x)h(x)
		\end{equation*}
		for some $h(x) \in \mathbb{C}[x].$ However, since $f(x)$ and $g(x)$ are both real polynomials, so is $h(x).$ \hfill (Why?)\\
		Thus, we get that
		\begin{equation*} 
			f(x) = g(x)h(x)
		\end{equation*}
		for real polynomials $g(x)$ and $h(x).$ Moreover, note that $\deg g(x) = 2$ and $\deg h(x) = n - 2 \ge 1.$ Thus, both are non-constant.
	\end{soln}
	%\\
	%\\
	%
	\item Show that if $U$ is a path connected open set in $\mathbb{C},$ so is $U$ minus any finite set.
	%
	\begin{soln}
		We will first prove the following claim:
		\begin{blockquote}
			\textbf{Claim:} Let $U \subset \mathbb{C}$ be open and $w \in U.$ Then, $U \setminus \{w\}$ is open.
			\begin{proof} 
				Let $z_0 \in U\setminus\{w\}$ be arbitrary. Since $U$ was open, there exists $\delta_1 > 0$ such that
				\begin{equation*} 
					B_{\delta_1}(z_0) \subset U.
				\end{equation*}
				Since $z_0 \neq w,$ we have that $\delta_2 \vcentcolon= |z_0 - w| > 0.$\\
				Choose $\delta := \min\{\delta_1, \delta_2\}.$ Clearly, $\delta > 0.$ Moreover, we have
				\begin{equation*} 
					w \notin B_{\delta_2}(z_0) \supset B_{\delta}(z_0)
				\end{equation*}
				and thus, $w \notin B_{\delta}(z_0).$ Also,
				\begin{equation*} 
					B_{\delta}(z_0) \subset B_{\delta_1}(z_0) \subset U.
				\end{equation*}
				Thus, we get that
				\begin{equation*} 
					B_{\delta}(z_0) \subset U \setminus \{w\},
				\end{equation*}
				proving that $U\setminus\{w\}$ is open.
			\end{proof}
		\end{blockquote}
		By the above proof, we see that removing one point from an open set keeps it open. Thus, if we show that removing one point from an open path-connected set leaves it path-connected, then we are done since we can induct to get any other \textbf{finite}\footnote{Finiteness is important. Induction cannot prove this result for a countably infinite set.} set.\\~\\
		Thus, we now show that if $U$ is open and path-connected, so is $U\setminus\{w\}.$ (Where $w \in U$ is any arbitrary element.)\\~\\
		Let $z_0, z_1 \in U\setminus\{w\}.$ We wish to show that there is a path in $U\setminus\{w\}$ connecting $z_0$ to $z_1.$\\
		Since $U$ was path-connected to begin with, there exists a path $\sigma:[0, 1] \to U$ such that
		\begin{equation*} 
			\sigma(0) = z_0, \quad \sigma(1) = z_1.
		\end{equation*}
		If $\sigma(x) \neq w$ for any $x \in [0, 1],$ then we are done since $\sigma$ is a path in $U\setminus\{w\}$ as well.\\
		Suppose that this is not the case.\\
		Then, we choose a $\delta > 0$ such that the \emph{closed} ball
		\begin{equation*} 
			B \vcentcolon= \{z \in \mathbb{C} : |z - w| \le \delta\}
		\end{equation*}
		has the following properties:
		\begin{enumerate}
			\item $z_0 \notin B,$
			\item $z_1 \notin B,$
			\item $B \subset U.$
		\end{enumerate}
		(Why must such a $\delta$ exist? There exists a $\delta_1$ for which we get the first two properties since $z_0$ and $z_1$ are distinct from $w.$ For the last property, let $\delta_2$ be any such that $B_{\delta_2}(w) \subset U,$ which exists since $U$ is open. Then, consider $\delta_2/2.$ The \emph{closed} ball of this radius must again be completely within $U.$ Take the minimum of $\delta_1$ and $\delta_2/2$.)\\~\\
		Note that
		\begin{equation*} 
			\sigma^{-1}(B) = \{x \in [0, 1] : \sigma(x) \in B\}
		\end{equation*}
		is nonempty since $w \in B$ and $\sigma(c) = w$ for some $c \in [0, 1],$ by our assumption. \\
		Moreover, $\sigma^{-1}(B)$ must be closed. (Why?)\\
		Since it is a subset of $[0, 1],$ it is clearly bounded. Define
		\begin{equation*} 
			s \vcentcolon= \inf \sigma^{-1}(B), \quad t \vcentcolon= \sup\sigma^{-1}(B).
		\end{equation*}
		Since the set is closed, both $s$ and $t$ are elements of $\sigma^{-1}(B).$ Note that $\sigma(0) \notin B$ and $\sigma(1) \notin B$ and thus,
		\begin{equation*} 
			0 < s < t < 1.
		\end{equation*}
		(Why is the inequality $s < t$ strict?)\\
		Note that $\sigma(s)$ and $\sigma(t)$ must lie on the circumference of $B.$ (Why?) (This also shows why $s < t.$)\\
		Now consider the path $\sigma':[0, 1] \to U$ defined as follows:
		\begin{equation*} 
			\sigma'(x) = \begin{cases}
				\sigma(x) & \text{if } x \in [0, s] \cup [t, 1]\\
				\gamma(x) & \text{if } x \in [s, t],
			\end{cases}
		\end{equation*}	
		where $\gamma:[s, t] \to B$ is the path which is the arc joining $\sigma(s)$ to $\sigma(t).$ (Note that $\sigma(s) = \sigma(t)$ is possible in which case, it's the constant path.)\\
		Clearly, $\sigma'$ avoids $w$ and is continuous. \hfill (Why?)\\~\\
		Moreover, $\sigma'(0) = \sigma(0) = z_0$ and $\sigma'(1) = \sigma(1) = z_1$ and thus, $\sigma'$ is a path from $z_0$ to $z_1$ in $U \setminus \{w\},$ showing that $U\setminus\{w\}$ is path-connected.
	\end{soln}
	%\\
	%\\
	%\\
	%
	\item Check for real differentiability and holomorphicity:
	\begin{enumerate}
		\item $f(z) = c,$
		\item $f(z) = z,$
		\item $f(z) = z^n,$ $n \in \mathbb{Z},$
		\item $f(z) = \Re z,$
		\item $f(z) = \left|z\right|,$
		\item $f(z) = \left|z\right|^2,$
		\item $f(z) = \bar{z},$
		\item $f(z) = \begin{cases}
		\dfrac{z}{\bar{z}} & \text{if } z \neq 0,\\
		0 & \text{if } z = 0.
		\end{cases}$
	\end{enumerate}
	%
	\begin{soln}
		Not going to do all.
		\begin{enumerate}
			\item Real differentiable and holomorphic, both.
			\item Real differentiable and holomorphic, both.
			\item For $n \ge 0:$\\
			Real differentiable and holomorphic, both. Let us see why.\\
			As we know, holomorphicity implies real differentiability, so we only check that $f$ is holomorphic on $\mathbb{C}.$\\
			Let $z_0 \in \mathbb{C}$ be arbitrary. We show that the limit
			\begin{equation*} 
				\lim_{z\to z_0}\dfrac{f(z) - f(z_0)}{z - z_0}
			\end{equation*}
			exists.\\
			This is clear because for $z_0 \neq z,$ we have
			\begin{equation*} 
				\dfrac{z^n - z_0^n}{z - z_0} = \sum_{k=0}^{n-1}z^kz_0^{n - 1 - k}.
			\end{equation*}
			The limit $z \longrightarrow z_0$ of the RHS clearly exists.\\~\\
			$n < 0:$ The function is now defined on $\mathbb{C}\setminus\{0\}.$ It is still holomorphic and real differentiable everywhere (in its domain!).\\
			To see this, we just use the quotient rule and appeal to the previous case of $n \ge 0.$
			\item Real differentiable but not holomorphic. Note that $f$ can be written as
			\begin{equation*} 
				f(x + \iota y) = x + 0\iota.
			\end{equation*}
			Thus, $u(x, y) = x$ and $v(x, y) = 0.$\\
			This is clearly real differentiable everywhere since all the partial derivatives exist everywhere and are continuous.\\
			However, we show that $f$ is not complex differentiable at any point. Thus, it is not holomorphic.\\
			This is easy because one sees that $u_x(x_0, y_0) = 1$ and $v_y(x_0, y_0) = 0$ for all $(x_0, y_0) \in \mathbb{R}^2$ and thus, the CR equations don't hold.
			\item $|z|$ is real differentiable everywhere except $0$ and complex differentiable nowhere. Breaking the function as earlier, we have
			\begin{equation*} 
				u(x, y) = \sqrt{x^2 + y^2}, \quad v(x, y) = 0.
			\end{equation*}
			On $\mathbb{R}^2\setminus\{(0, 0)\},$ all partial derivatives exist and are continuous. At $(0, 0),$ $u_x$ and $u_y$ fail to exist.\\~\\
			This clearly shows that $f$ is not complex differentiable at $0 \in \mathbb{C}$ since it is not even real differentiable there.\\
			However, we see that $v_y = 0 = v_x$ everywhere else but at least one of $u_x$ or $u_y$ is nonzero on $\mathbb{R}^2\setminus\{(0, 0)\}$ and thus, the CR equations prevent $f$ from being complex differentiable anywhere else.
			%
			\item Real differentiable everywhere.\\
			Complex differentiable precisely at $0.$\\
			Holomorphic nowhere.\\~\\
			Same steps as above.
			%
			\item Real differentiable everywhere. Complex differentiable nowhere. Use CR equations again.
			%
			\item 
			$f$ is real differentiable precisely on $\mathbb{R}^2\setminus\{(0, 0)\}.$\\
			However, it is not complex differentiable anywhere.\\~\\
			Breaking as earlier, we get
			\begin{equation*} 
				u(x, y) = \dfrac{x^2 - y^2}{x^2 + y^2}, \quad v(x, y) = \dfrac{2xy}{x^2 + y^2},
			\end{equation*}
			for $(x, y) \in \mathbb{R}^2\setminus\{(0, 0)\}$ and
			\begin{equation*} 
				u(0, 0) = 0 = v(0, 0).
			\end{equation*}
			Note that $u$ and $v$ aren't even continuous at $(0, 0).$ Thus, neither if $f.$ Hence, $f$ is neither real nor complex differentiable at $(0, 0).$ \\
			However, at all other points, all partial derivatives exist and are continuous. Thus, $f$ is real differentiable at all those points. However, computing $u_x, u_y, v_x, v_y$ explicitly shows that the CR equations are not satisfied anywhere. Thus, $f$ is not complex differentiable anywhere. \qedhere
		\end{enumerate}
	\end{soln}
	%
	%
	%
	\item  Show that the CR equations take the form
	\begin{equation*} 
		u_r = \dfrac{1}{r}v_\theta, \quad v_r = -\dfrac{1}{r}u_\theta
	\end{equation*}
	in polar coordinates.
	%\\
	\begin{soln}
		We shall follow the same idea as in the slides. We first write
		\begin{equation*} 
			f(r, \theta) = f(re^{\iota\theta}) = u(r, \theta) + \iota v(r, \theta).
		\end{equation*}
		Suppose that $f$ is differentiable at $z_0 = r_0e^{\iota\theta_0} \neq 0.$ (Note that it wouldn't make sense to talk at $0$ since there's a $r^{-1}$ factor in the question anyway.)\\
		Thus, we know that the limit
		\begin{equation*} 
			\lim_{z\to z_0}\dfrac{f(z) - f(z_0)}{z - z_0}
		\end{equation*}
		exists. We shall calculate it in two ways:
		\begin{enumerate}
			\item Fix $\theta = \theta_0$ and let $r \to r_0.$ Then, we get
			\begin{align*} 
				f'(z_0) &= \lim_{r\to r_0}\left\{\dfrac{u(r, \theta_0) - u(r_0, \theta_0)}{e^{\iota\theta_0}(r - r_0)} + \iota\dfrac{v(r, \theta_0) - v(r_0, \theta_0)}{e^{\iota\theta_0}(r - r_0)}\right\}\\~\\
				&= e^{-\iota\theta_0}\lim_{r\to r_0}\left\{\dfrac{u(r, \theta_0) - u(r_0, \theta_0)}{r - r_0} + \iota\dfrac{v(r, \theta_0) - v(r_0, \theta_0)}{r - r_0}\right\}\\~\\
				&= e^{-\iota\theta_0}\left(u_r(r_0, \theta_0) + \iota v_r(r_0, \theta_0)\right). & (*)
			\end{align*}

		\item Fix $r = r_0$ and let $\theta \to \theta_0.$ Then, we get
		\begin{align*} 
			f'(z_0) &= \lim_{\theta\to \theta_0}\left\{\dfrac{u(r_0, \theta) - u(r_0, \theta_0)}{r_0(e^{\iota\theta} - e^{\iota\theta_0})} + \iota\dfrac{v(r_0, \theta) - v(r_0, \theta_0)}{r_0(e^{\iota\theta} - e^{\iota\theta_0})}\right\}\\~\\
			&= \dfrac{1}{r_0}\lim_{\theta\to \theta_0}\left\{\dfrac{u(r_0, \theta) - u(r_0, \theta_0)}{e^{\iota\theta} - e^{\iota\theta_0}} + \iota\dfrac{v(r_0, \theta) - v(r_0, \theta_0)}{e^{\iota\theta} - e^{\iota\theta_0}}\right\} & (**)
		\end{align*}
		We concentrate on the first term of the limit. Note that
		\begin{align*} 
			&\lim_{\theta\to \theta_0}\dfrac{u(r_0, \theta) - u(r_0, \theta_0)}{e^{\iota\theta} - e^{\iota\theta_0}}\\~\\
			=& \lim_{\theta\to \theta_0}\dfrac{u(r_0, \theta) - u(r_0, \theta_0)}{\theta - \theta_0}\dfrac{\theta - \theta_0}{e^{\iota\theta} - e^{\iota\theta_0}}.
		\end{align*}
		In the product, the first term is clearly $u_\theta(r_0, \theta_0),$ after taking the limit. The second term can be calculated to be
		\begin{equation*} 
			\dfrac{1}{\iota e^{\iota\theta_0}}.
		\end{equation*}
		(How? Write $e^{\iota\theta}$ in terms of $\cos$ and $\sin$ and differentiate those and put it back.)\\
		Of course, a similar argument goes through for the $v$ term as well.\\
		Thus, we get that $(**)$ transforms to
		\begin{equation*} 
			f'(z_0) = \dfrac{e^{-\iota\theta_0}}{r_0}\left(\iota u_\theta(r_0, \theta_0) + v_\theta(r_0, \theta_0)\right).
		\end{equation*}
		\end{enumerate}
		Equating the above with $(*),$ cancelling $e^{-\iota\theta_0},$ and comparing the real and imaginary parts, we get
		\begin{equation*} 
			u_r(r_0, \theta_0) = \dfrac{1}{r_0}v_\theta(r_0, \theta_0), \quad v_r(r_0, \theta_0) = -\dfrac{1}{r_0}u_\theta(r_0, \theta_0),
		\end{equation*}
		as desired.
	\end{soln}
\end{enumerate}
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%

\newpage\section{Tutorial 2}
\begin{center}
	1st September, 2020
\end{center}
\begin{enumerate}
	\item  If $u(X,Y)$ and $v(X,Y)$ are harmonic conjugates of each other, show that they are constant functions.\\
	Remark (my own): This is true iff $u$ and $v$ are defined on domains, that is, open and path-connected sets.
	\begin{soln}
		Since $v$ is a harmonic conjugate of $u,$ we get that
		\begin{equation*} 
			u_X = v_Y, \quad u_Y = -v_X.
		\end{equation*}
		On the other hand, since $u$ is a harmonic conjugate of $v,$ we get that
		\begin{equation*} 
			v_X = u_Y, \quad v_Y = -u_X.
		\end{equation*}
		(Note that the equalities mean that they're true for every $(X_0, Y_0)$ in the domain.)\\
		Thus, we get that
		\begin{equation*} 
			u_X = u_Y = v_X = v_Y \equiv 0,
		\end{equation*}
		identically. \\
		Since the domain is connected, this implies that $u$ and $v$ are constant.
	\end{soln}
	%
	\item Show that $u = XY - 3X^2Y - Y^3$ is harmonic and find its harmonic conjugate.
	\begin{soln} \phantom{hi}\\	
		\textbf{Smart way:} If we can show that the above function is the real (or imaginary) part of a holomorphic function $f,$ then we have shown that $u$ is harmonic.\\
		Writing $Z = X + iY,$ it is not too tough to see that the above is the \textbf{imaginary} part of $\frac{1}{2}Z^2 + Z^3.$ Since
		\begin{equation*} 
			f(Z) = \dfrac{1}{2}Z^2 + Z^3
		\end{equation*}
		is holomorphic on $\mathbb{C},$ this gives us that $u$ is harmonic.\\
		This also shows \emph{a} harmonic conjugate of $u$ is 
		\begin{equation*} 
			v(X, Y) = -\Re f(Z) = \dfrac{1}{2}(Y^2 - X^2) + 3XY^2 - X^3.
		\end{equation*}
		(Note the negative sign! If we had gotten $u$ as the \emph{real} part of a holomorphic function, then for finding harmonic conjugate, we would've simply taken the imaginary part \emph{without} the negative sign.)

		\dotfill

		\textbf{Laborious way:} This is the way to do it if observing is difficult.\\
		First, we show that $u$ is harmonic by manual calculation. Note that
		\begin{equation*} 
			u_{XX}(X_0, Y_0) = 6Y_0 \text{ and } u_{YY}(X_0, Y_0) = -6Y_0.
		\end{equation*} 
		Thus, $u_{XX} + u_{YY} \equiv 0$ and $u$ is indeed harmonic.\\~\\
		To find its harmonic conjugate, we perform the procedure as given in slides.\\
		Note that $u_X = v_Y.$ Here, we get $u_X = Y + 6XY = v_Y.$\\
		Integrating with respect to $Y$ gives us
		\begin{equation*} 
			v = \dfrac{1}{2}Y^2 + 3XY^2 + g(X)
		\end{equation*}
		for some function $g.$ Then, we need $v_X = -u_Y.$ Computing each individually, we get
		\begin{equation*} 
			3Y^2 + g'(X) = -X - 3X^2 + 3Y^2.
		\end{equation*}
		Thus, up to a constant, we get
		\begin{equation*} 
			g(X) = -\dfrac{1}{2}X^2 - X^3.
		\end{equation*}
		Finally, this gives
		\begin{equation*} 
			v = \dfrac{1}{2}Y^2 + 3XY^2 - \dfrac{1}{2}X^2 - X^3. \qedhere
		\end{equation*}
	\end{soln}
	%\\
	%\\
	\item Find the radius of convergence of the following power series:
	\begin{enumerate}
		\item $\displaystyle\sum_{n=0}^{\infty}nz^n,$
		\item $\displaystyle\sum_{p \text{ prime}} z^p,$
		\item $\displaystyle\sum_{n=1}^{\infty}\dfrac{n!}{n^n}z^n.$
	\end{enumerate}
	\begin{soln}
		We shall be using the root test in the first two cases and ratio test in the third. \\
		One thing to recall is that \emph{if} the limit $\displaystyle\lim_{n\to \infty}a_n$ exists, \emph{then} $\displaystyle\limsup_{n\to\infty}a_n$ is equal to that limit. This will be helpful in the first and third parts since the limits will themselves exist.\\
		Moreover, we recall that if
		\begin{equation*} 
			\alpha = \limsup_{n\to\infty}\sqrt[n]{|a_n|},
		\end{equation*}
		then the radius of convergence $R$ is given by
		\begin{equation*} 
			R = \alpha^{-1}.
		\end{equation*}
		(The case $\alpha = 0$ corresponds to $R = \infty$ and vice-versa.)\\
		Similar analysis holds for
		\begin{equation*} 
			\alpha = \lim_{n \to \infty}\left|\dfrac{a_{i+1}}{a_i}\right|.
		\end{equation*}
		(Here, however, note that I need the existence of $\alpha.$ In the case of $\limsup,$ that was always guaranteed.)
		\begin{enumerate}
			\item Note that we have
			\begin{equation*} 
				\lim_{n\to \infty}\sqrt[n]{n} = 1.
			\end{equation*}
			(MA 105 Tutorial Sheet 1, Question 2 (iv))\\~\\
			Thus, we also have
			\begin{equation*} 
				\alpha = \limsup_{n\to\infty}\sqrt[n]{n} = 1
			\end{equation*}
			and thus,
			\begin{equation*} 
				R = \alpha^{-1} = \boxed{1.}
			\end{equation*}
			\item Note that first we can rewrite the series in the form
			\begin{equation*} 
				\sum_{n=1}^{\infty}a_nz^n,
			\end{equation*}	
			where
			\begin{equation*} 
				a_n \vcentcolon= \begin{cases}
					0 & n \text{ is not a prime,}\\
					1 & n \text{ is a prime.}
				\end{cases}
			\end{equation*}
			For this, we clearly have
			\begin{equation*} 
				\limsup_{n\to\infty}\sqrt[n]{|a_n|} = \lim_{n\to \infty}1 = 1.
			\end{equation*}
			(To see this, note that there are infinitely many primes and thus, given any $n,$ there exists $m \ge n$ such that $a_m = 1.$)\\
			Thus, as before, the radius of convergence is $1.$
			\item Here, we have
			\begin{equation*} 
				a_n = \dfrac{n!}{n^n}.
			\end{equation*}
			Thus, we get
			\begin{align*} 
				\alpha = \lim_{n\to \infty}\left|\dfrac{a_{n+1}}{a_n}\right| &= \lim_{n\to \infty}(n + 1)\dfrac{n^n}{(n + 1)^{n + 1}}\\
				&= \lim_{n\to \infty}\left(1 + \dfrac{1}{n}\right)^{-n}\\
				&= e^{-1}.
			\end{align*}
			Thus, the limit actually exists and we get
			\begin{equation*} 
				R = \alpha^{-1} = \boxed{e.} \qedhere
			\end{equation*}
		\end{enumerate}
	\end{soln}
	%\\
	%\\
	%
	\item Show that $L > 1$ in the ratio test (Lecture 3 slides) does not necessarily imply that the series is divergent.
	\begin{soln}
		Consider the sequence
		\begin{equation*} 
			\dfrac{1}{1^3},\;\dfrac{1}{1^2},\;\dfrac{1}{2^3},\;\dfrac{1}{2^2},\;\ldots,\;\dfrac{1}{n^3},\;\dfrac{1}{n^2},\;\ldots.
		\end{equation*}
		That is, let $(a_n)$ be the sequence defined by
		\begin{equation*} 
			a_{2n} = \dfrac{1}{n^2}, \quad a_{2n - 1} = \dfrac{1}{n^3}.
		\end{equation*}
		Note that $\sum a_n$ converges, since $\sum n^{-2}$ and $\sum n^{-3}$ converge. (This can be checked via the integral test.)\\
		On the other hand, note that that 
		\begin{equation*} 
			L = \limsup_{n \to \infty}\left|\dfrac{a_{n + 1}}{a_n}\right| \ge \limsup_{n \to \infty}\left|\dfrac{a_{2n}}{a_{2n - 1}}\right| = \limsup_{n \to \infty} n = \infty.
		\end{equation*}
		Thus, $L = \infty,$ clearly $> 1.$\\
		(So, not only did we show that $L > 1$ doesn't imply {\color{myupdatecolor}divergence} but also that even $L = \infty$ is not good enough to conclude divergence.)
	\end{soln}
	%
	%
	%
	\item Construct a infinitely differentiable function $f:\mathbb{R}\to\mathbb{R}$ which is non-zero but vanishes outside a bounded set. Show that there are no holomorphic functions which satisfy this property.
	%
	\begin{soln}
		Recall the function $g:\mathbb{R}\to\mathbb{R}$ from the lectures given as
		\begin{equation*} 
			g(x) \vcentcolon= \begin{cases}
				0 & x \le 0,\\
				e^{-1/x} & x > 0.
			\end{cases}
		\end{equation*}
		As we saw, this is an infinitely differentiable function. Now, consider $f:\mathbb{R} \to \mathbb{R}$ defined as
		\begin{equation*} 
			f(x) \vcentcolon= g(x)g(1 - x).
		\end{equation*}
		Clearly, $f$ is infinitely differentiable, being the product of two such functions. Moreover, $f(x) = 0$ if $x \le 0$ or $x \ge 1.$ In other words, $f$ is $0$ outside the bounded set
		\begin{equation*} 
			(0, 1).
		\end{equation*}
		However, $f$ is non-zero since
		\begin{equation*} 
			f\left(\dfrac{1}{2}\right) = \left(g\left(\dfrac{1}{2}\right)\right)^2 = e^{-4} \neq 0.
		\end{equation*}
		On the other hand, let $f:\mathbb{C}\to\mathbb{C}$ be a holomorphic function which is zero outside some bounded set $K.$ We show that $g$ is zero everywhere. \\
		Since $K$ is bounded, there exists $M > 0$ such that
		\begin{equation*} 
			|z| \le M \quad \text{ for all } z \in K.
		\end{equation*}
		Thus, choosing the point $z_0 = M + 43,$ we see that $f$ is zero in the neighbourhood of $z_0$ of radius $42.$ \hfill (Why?)\\
		However, since $\mathbb{C}$ is (open and) path-connected, this implies that $f$ is zero \emph{everywhere}, as desired.
	\end{soln}
		
		\hrulefill
		
		Some more elaboration on the last part: In the lectures, we had seen the result that if $\Omega$ is a domain and $f:\Omega \to \mathbb{C}$ is analytic, then $f$ has the following property:

		\begin{mdframed}
			Either $f$ is identically zero or the zeroes of $f$ form a discrete set.
		\end{mdframed}

		Since any open disc is not discrete, we get that

		\begin{mdframed}
			\begin{equation*} 
				f \text{ is zero on a neighbourhood } \implies f \text{ is zero everywhere on }\Omega.
			\end{equation*}
		\end{mdframed}

		However, note that we had proved the result for analytic functions. As we shall see later in the course, holomorphic functions are indeed analytic.
	%\\
	%\\
	%
	\item Show that $\exp:\mathbb{C}\to\mathbb{C}^\times$ is onto.
	\begin{soln}
		Let $z_0 \in \mathbb{C}^\times.$ We show that $\exp(z) = z_0$ for some $z \in \mathbb{C}.$ \\
		Note that $r = |z_0| \neq 0.$\\
		Then,
		\begin{equation*} 
			w = \dfrac{z_0}{r}
		\end{equation*}
		has modulus $1.$ In other words,
		\begin{equation*} 
			w = x_0 + \iota y_0
		\end{equation*}
		for some $(x_0, y_0) \in \mathbb{R}^2$ such that $x_0^2 + y_0^2 = 1.$\\
		Thus, $x_0 = \cos\theta$ and $y_0 = \sin\theta$ for some $\theta \in [0, 2\pi).$\\~\\
		Define $z = \log(r) + \iota\theta.$ Note that this $\log$ is the real-valued $\log.$ Thus, we get
		\begin{align*} 
			\exp(z) = \exp(\log(r) + \iota\theta) &= \exp(\log(r))\cdot\exp(\iota\theta)\\
			&= r\cdot(\cos\theta + \iota\sin\theta)\\
			&= rw = z_0.
		\end{align*}
		Thus, $\exp$ is surjective.
	\end{soln}

	%\\
	%\\
	%\\
	\item Show that $\sin, \cos: \mathbb{C}\to\mathbb{C}$ are surjective. (In particular, note the difference with real sine and cosine which were bounded by $1$).
	%
	\begin{soln}
		We show this for $\cos.$ The method works the same for $\sin.$\\
		Recall that
		\begin{equation*} 
			\cos(z) = \dfrac{1}{2}\left(e^{\iota z} + e^{-\iota z}\right).
		\end{equation*}
		Let $z_0 \in \mathbb{C}.$ We show that $\cos(z) = z_0$ for some $z \in \mathbb{C}.$\\
		Consider the quadratic equation
		\begin{equation*} 
			\dfrac{1}{2}\left(t + \dfrac{1}{t}\right) = z_0. \quad (*)
		\end{equation*}
		Rearranging this gives
		\begin{equation*} 
			t^2 - 2z_0t + 1 = 0.
		\end{equation*}
		Note that the above has complex solutions $t_1$ and $t_2.$ (Since every complex number has a square root in $\mathbb{C}$!)\\
		Moreover, note that $t_1 \neq 0.$ Thus, by the previous part, there exists $z \in \mathbb{C}$ such that $e^z = t_1.$ {\color{myupdatecolor}Considering $z' = z/\iota,$ we get that $e^z = e^{\iota z'} = t_1.$ \\
				Plugging $t_1 = e^{\iota z'}$ in $(*)$ shows that
				\begin{equation*} 
					\cos(z') = z_0,
				\end{equation*}
				as desired.	}
	\end{soln}
	%
	%
	\item Show that for any complex number $z,$ $\sin^2(z) + \cos^2(z) = 1.$
	\begin{soln}
		Recall the definitions
		\begin{equation*} 
			\iota\sin(z) = \dfrac{1}{2}\left(e^{\iota z} - e^{-\iota z}\right), \quad \cos(z) = \dfrac{1}{2}\left(e^{\iota z} + e^{-\iota z}\right).
		\end{equation*}
		Squaring and subtracting gives
		\begin{equation*} 
			(\cos(z))^2 - (\iota\sin(z))^2 = \dfrac{1}{4}(4e^{\iota z}e^{-\iota z}) = 1
		\end{equation*}
		or
		\begin{equation*} 
			\sin^2(z) + \cos^2(z) = 1.
		\end{equation*}

		\dotfill

		{\color{myupdatecolor}\textbf{Smarter way:} Consider the function $f:\mathbb{C}\to\mathbb{C}$ defined as 
				\begin{equation*} 
					f(z) = \cos^2z + \sin^2z - 1.
				\end{equation*}
				This is analytic and vanishes on $\mathbb{R}.$ Since $\mathbb{R}$ is not discrete, it must vanish everywhere.}
	\end{soln}
\end{enumerate}
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%

\newpage\section{Tutorial 3}
\begin{center}
	8th September, 2020
\end{center}

\begin{enumerate}
	\item Let $\gamma$ be the boundary of the triangle
	\begin{equation*} 
		\{0 < y < 1 - x; 0 \le x \le 1\}
	\end{equation*}
	taken with the anticlockwise orientation. 

	\begin{center}
		\begin{tikzpicture}
			\def \len{3};
			\def \del{0.3};
			\draw[thick, -<-=at 0.5 with label {$\gamma_1$}](\len, 0) -- (0, 0);
			\draw[thick, -<-=at 0.5 with label {$\gamma_2$}](0, \len) -- (\len, 0);
			\draw[thick, -<-=at 0.5 with label {$\gamma_3$}](0, 0) -- (0, \len);
			\node[] at (-\del, -\del) {$(0, 0)$};
			\node[] at (\len + \del, -\del) {$(1, 0)$};
			\node[] at (0, \len + \del) {$(0, 1)$};
		\end{tikzpicture}
	\end{center}

	Evaluate:
	\begin{enumerate}
		\item $\displaystyle\int_\gamma\Re(z)dz$\\~\\
		Note that we can compute the integrals along $\gamma_1, \ldots, \gamma_3$ and then add them.\\
		Along $\gamma_3,$ the integral must be $0$ since $\Re(z) = 0$ along that curve.\\
		Along $\gamma_1,$ we parameterise the curve as
		\begin{equation*} 
			\gamma_1(t) = t + 0\iota, \quad \text{for } t \in [0, 1].
		\end{equation*}
		Then, we get that $\gamma_1'(t) = 1 + 0\iota.$ Thus, the integral is calculated as
		\begin{align*} 
			\int_{\gamma_1}\Re(z){\mathrm{d}}z &= \int_{0}^{1} \Re(\gamma_1(t))\gamma_1'(t) {\mathrm{d}}t\\
			&= \int_{0}^{1} t {\mathrm{d}}t\\
			&= \dfrac{1}{2}.
		\end{align*}

		Similarly, we compute the integral along $\gamma_2.$ First, we parameterise it as
		\begin{equation*} 
			\gamma_2(t) = 1 - t + \iota t, \quad \text{for } t \in [0, 1].
		\end{equation*}
		We compute the derivative as $\gamma_2'(t) = -1 + \iota.$ Thus, the integral is calculated as
		\begin{align*} 
			\int_{\gamma_2}\Re(z){\mathrm{d}}z &= \int_{0}^{1} \Re(\gamma_2(t))\gamma_2'(t) {\mathrm{d}}t\\
			&= \int_{0}^{1} (1 - t)(-1 + \iota) {\mathrm{d}}t\\
			&= \dfrac{1}{2}(\iota - 1).
		\end{align*}
		Thus, we get the overall integral as
		\begin{equation*} 
			\int_{\gamma}^{} \Re(z) {\mathrm{d}}z = \boxed{\dfrac{\iota}{2}}.
		\end{equation*}
		\item $\displaystyle\int_{\gamma}^{} z^2 {\mathrm{d}}z.$\\~\\
		Note that $\gamma$ is a closed curve and $z^2$ admits a primitive on $\mathbb{C}.$ Thus, we get that the integral is $\boxed{0}.$
	\end{enumerate}
	%	
	\item Compute $\displaystyle\int_{|z - 1| = 1}^{} \dfrac{2z - 1}{z^2 - 1} {\mathrm{d}}z.$

	Remark (my own): If nothing is specified, we assume that the integral is in the counterclockwise sense.

	\begin{soln}
		Note that the curve of integration does not enclose $-1.$ Keeping this in mind, we define
		\begin{equation*} 
			f:\mathbb{C}\setminus\{-1\} \to \mathbb{C}
		\end{equation*}	
		as 
		\begin{equation*} 
			f(z) = \dfrac{2z - 1}{z + 1}.
		\end{equation*}
		Note that this is holomorphic on $\Omega = \mathbb{C}\setminus\{-1\}.$ Moreover, $\gamma$ and its interior lie completely within $\Omega.$ Thus, using the Cauchy integral formula, we see that (assuming the circle is traverses counterclockwise)
		\begin{equation*} 
			2\pi\iota f(1) = \int_{|z - 1| = 1}^{} \dfrac{f(z)}{z - 1} {\mathrm{d}}z.
		\end{equation*}
		However, note that the integral on the right is precisely what we wish to calculate. Thus, we get the desired integral's value as
		\begin{equation*} 
			2\pi\iota f(1) = \boxed{\pi\iota}. \qedhere
		\end{equation*}
	\end{soln}
	%
	\item Show that if $\gamma$ is a simple closed curve traced counterclockwise, the integral $\displaystyle\int_{\gamma}^{} \bar{z} {\mathrm{d}}z$ equals $2\iota\operatorname{Area}(\gamma).$\\
	Evaluate $\displaystyle\int_{\gamma}^{} \bar{z}^m {\mathrm{d}}z$ over a circle $\gamma$ centered at the origin.
	\begin{soln}
		Suppose that $\gamma(t) = x(t) + \iota y(t)$ for $t \in [a, b].$
		\begin{align*} 
			\displaystyle\int_{\gamma}^{} \bar{z} {\mathrm{d}}z &= \int_{a}^{b} \overline{\gamma(t)}\gamma'(t) {\mathrm{d}}t\\
			&= \int_{a}^{b} (x(t) - \iota y(t))(x'(t) + \iota y'(t)) {\mathrm{d}}t\\
			&= \int_{a}^{b} (x(t)x'(t) + y(t)y'(t)) {\mathrm{d}}t + \iota\int_{a}^{b} (x(t)y'(t) - y(t)x'(t)) {\mathrm{d}}t\\
			&= \int_{\gamma}(x{\mathrm{d}}x + y{\mathrm{d}}y) + \iota\int_{\gamma}(x{\mathrm{d}}y - y{\mathrm{d}}x)\\
			&= \iint_{\operatorname{Int}(\gamma)}(0 - 0){\mathrm{d}}(x, y) + \iota\iint_{\operatorname{Int}(\gamma)}(1 - (-1)){\mathrm{d}}(x, y)\\
			&= 2\iota\iint_{\operatorname{Int}(\gamma)}{\mathrm{d}}(x, y)\\
			&= 2\iota\operatorname{Area}(\gamma).
		\end{align*}
		In going from the single integral to the double integral, we used Green's theorem which said that
		\begin{equation*} 
			\int_{\gamma}(M{\mathrm{d}}x + N{\mathrm{d}}y) = \iint_{\operatorname{Int}(\gamma)} \left(\dfrac{\partial N}{\partial x} - \dfrac{\partial M}{\partial y}\right) {\mathrm{d}}(x, y)
		\end{equation*}
		if $\gamma$ is a (nice-enough) closed curve oriented counterclockwise. (Here is where we have used orientation.)\\
		{\color{myupdatecolor}As usual, $\operatorname{Int}(\gamma)$ denotes the ``interior'' of $\gamma.$ (Recall Jordan's curve theorem which says that every simple closed curve divides the plane (minus the curve) into two path-connected components, one bounded and one unbounded. The ``interior'' is the bounded component.)}

		For the second part, we simply parameterise the curve as
		\begin{equation*} 
			\gamma(t) = r(\cos t + \iota \sin t), \quad \text{for } t \in [0, 2\pi],
		\end{equation*}
		where $r > 0$ is arbitrary.

		We see that $\gamma'(t) = r(-\sin t + \iota\cos t) = \iota\gamma(t).$ \\
		Thus, we get

		\begin{align*} 
			\int_{\gamma}^{} \bar{z}^m {\mathrm{d}}z &= \int_{0}^{2\pi} \overline{(\gamma(t))}^m \gamma'(t) {\mathrm{d}}t\\
			&= \int_{0}^{2\pi} \overline{(\gamma(t))}^{m-1} \cdot \overline{\gamma(t)} \gamma'(t) {\mathrm{d}}t\\
			&= \int_{0}^{2\pi} \overline{(\gamma(t))}^{m-1} \cdot \overline{\gamma(t)} \iota\gamma(t) {\mathrm{d}}t\\
			&= \iota\int_{0}^{2\pi} \overline{(\gamma(t))}^{m-1} \cdot \left|\gamma(t)\right|^2 {\mathrm{d}}t\\
			&= \iota r^2\int_{0}^{2\pi} r^{m-1}(\cos((m-1)t) - \iota\sin((m-1)t)) {\mathrm{d}}t
		\end{align*}
		Note that the $\sin$ integral is $0$ regardless of $m.$ However, the $\cos$ integral is $0$ iff $m \neq 1.$ If $m = 1,$ then we get that
		\begin{equation*} 
			\int_{0}^{2\pi} \cos(0t) {\mathrm{d}}t = 2\pi.
		\end{equation*}
		Thus, we get
		\begin{equation*} 
			\int_{\gamma}^{} \bar{z}^m {\mathrm{d}}z = \begin{cases}
				2\pi\iota r^2 & m = 1,\\
				0 & m \neq 1.
			\end{cases}
		\end{equation*}
	\end{soln}
	%
	%
	\item Let $\mathbb{H} = \{z \in \mathbb{C} \mid \Re(z) > 0\}$ be the (strict) open right half plane. Construct a {\color{myupdatecolor}non-constant} function $f$ which is holomorphic on $\mathbb{H}$ such that $f\left(\frac{1}{n}\right) = 0$ for all $n \in \mathbb{N}.$\\
	Note that the {\color{myupdatecolor}coloured} part is my addition.
	\begin{soln}
		Define 
		\begin{equation*} 
			f(z) \vcentcolon= \sin\left(\dfrac{\pi}{z}\right).
		\end{equation*}
		Since $0 \notin \mathbb{H},$ we see that $f$ is a composition of holomorphic functions and hence, is holomorphic. Moreover, one see that for any $n \in \mathbb{N},$ we have
		\begin{equation*} 
			f\left(\dfrac{1}{n}\right) = \sin(n\pi) = 0,
		\end{equation*}
		as desired. Lastly, $f$ is non-constant since
		\begin{equation*} 
			f(2) = \sin\left(\dfrac{\pi}{2}\right) = 1 \neq 0. \qedhere
		\end{equation*}
	\end{soln}
	%
	\item Let $f$ be a holomorphic function on $\mathbb{C}$ such that $f\left(\frac{1}{n}\right) = 0$ for all $n \in \mathbb{N}.$ Show that $f$ is constant.
	\begin{soln}\phantom{hi}\\
		\begin{blockquote}
		Motivation: We would like to appeal to the theorem about analytic (and hence, holomorphic) functions which said that if the set of zeroes of $f$ is not discrete, then $f$ is identically zero. However, we cannot directly use that result since $\{n^{-1} : n \in \mathbb{N}\}$ is in fact, a discrete set.\\
		However, the difference here is that $0$ is in the domain and $0$ is a ``limit point'' of the above set. We shall use this to our advantage.

		It may be useful to ``recall'' the definition:

		\begin{defn}[Discrete Set]
			A set $S \subset \Omega$ is said to be \emph{discrete} if for every $s \in S,$ there exists some $\delta > 0$ such that
			\begin{equation*} 
				B_\delta(s) \cap S = \{s\}.
			\end{equation*}
			In other words, for every $s \in S,$ there exists some $\delta > 0$ such that the $\delta$ neighbourhood of $s$ contains no other point of $S.$
		\end{defn}
		\end{blockquote}

		Note that $f$ is holomorphic. In particular, $f$ is continuous. Using this we see that
		\begin{align*} 
			f(0) &= f\left(\lim_{n\to \infty}\dfrac{1}{n}\right)\\
			&=\lim_{n\to \infty}f\left(\dfrac{1}{n}\right)\\
			&= \lim_{n\to \infty}0\\
			&= 0.
		\end{align*}
		(Note that here we know that $f$ is indeed defined at $0$ and thus, the above computations are valid.)

		\emph{Now}, we see that $f$ is zero on
		\begin{equation*} 
			S = \{0\}\cup\left\{\dfrac{1}{n} : n \in \mathbb{N}\right\}.
		\end{equation*}
		(It may be zero outside $S$ as well.)

		However, we see that $S$ is \emph{not} discrete. To see this, note that $0 \in S$ and given any $\delta > 0,$ there exists $n \in \mathbb{N}$ such that $1/n < \delta.$ Thus, for any $\delta > 0,$ we have that $B_\delta \cap S$ contains a point apart from $0.$ This shows that $S$ is not discrete.

		From this, we conclude that $f$ is identically zero. In particular, it is constant.
	\end{soln}
	%
	\item Expand $\displaystyle\dfrac{1 + z}{1 + 2z^2}$ into a power series around $0.$ Find the radius of convergence.
	\begin{soln}
		{\color{myupdatecolor} Note that I've changed the solution completely as since the first upload since I solved that with $1 + z^2$ in the numerator.}

		Let $f(z)$ denote the expression in the question.

		One may compute the power series by computing $f^{(n)}(0).$ However, if we already know a power series by some other means, we may directly use that. \\
		{\color{myupdatecolor}Recall that the power series expansion is unique.} Thus, if we know \emph{some} power series expansion with \emph{some} radius of convergence, that must be \emph{the} power series expansion with \emph{that} radius of convergence.\\
		{\color{myupdatecolor}Basically, if two different people compute two different sequence of coefficients with whatever methods, the coefficients and the radius of convergence will be equal.}\footnote{Maybe I am emphasising too much on something that isn't so crucial.}

		In this case, we have
		\begin{equation*} 
			\dfrac{1}{1 + 2z^2} = 1 - 2z^2 + (2z^2)^2 - (2z^2)^3 + \cdots
		\end{equation*}
		for $|2z^2| < 1$ or $|z| < \dfrac{1}{\sqrt{2}}.$

		Moreover, we do know that the series on the right diverges for $|z| > 1/\sqrt{2}.$ Thus, we get the power series of $f$ as

		\begin{align*} 
			f(z) &= (1 + z)(1 - 2z^2 + (2z^2)^2 - (2z^2)^3 + \cdots)\\
			&= (1 - 2z^2 + (2z^2)^2 - (2z^2)^3 + \cdots) + z(1 - 2z^2 + (2z^2)^2 - (2z^2)^3 + \cdots)\\
			&= 1 + z - 2z^2 - 2z^3 + 4z^4 + 4z^5 - 8z^6 - 8z^7 - \cdots,
		\end{align*}
		for $|z| < 1/\sqrt{2}.$ \\
		Moreover, multiplying with a non-zero finite power series will not change the radius of convergence. Thus, the radius of convergence is still $\boxed{\dfrac{1}{\sqrt{2}}}.$

		More concisely, we have
		\begin{equation*} 
			f(z) = \sum_{n=0}^{\infty}a_nz^n
		\end{equation*}
		where $a_n$ is given as $a_n = (-2)^{\lfloor n/2\rfloor}.$
	\end{soln}
	(As a double check, you may try to use the ratio test and compute the radius of convergence using that.)
\end{enumerate}	
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%

\newpage\section{Tutorial 4}
\begin{center}
	15th September, 2020
\end{center}

\begin{enumerate}
	\item Show that there is a strict inequality
	\begin{equation*} 
		\left|\int_{|z| = R}^{} \dfrac{z^n}{z^m - 1} {\mathrm{d}}z\right| < \dfrac{2\pi R^{n + 1}}{R^{m} - 1}; \quad R > 1,\; m \ge 1,\; n \ge 0.
	\end{equation*}

	\begin{soln}
		{\color{myupdatecolor}Here's another solution.}

		First, we look at the stronger ML inequality.
		\begin{thm}[The Stronger ML Inequality] \label{thm:stronkML}
			Let $f:\Omega\to\mathbb{C}$ be a continuous function and $\gamma:[a, b]\to\mathbb{C}$ be a curve.\\
			Let $M > 0$ be such that
			\begin{equation*} 
				M \ge f(\gamma(t)), \quad \text{for all } t \in [a, b].
			\end{equation*}
			Also, suppose that $|f(t)| < M$ for some $t \in [a, b].$ \\
			Then,
			\begin{equation*} 
				\int_{\gamma}^{} |f(z)| {\mathrm{d}}z < ML,
			\end{equation*}
			where $L$ is the length of the curve, as usual.
		\end{thm}
		That is, if $|f| < M$ holds for even one point, the $ML$ inequality becomes strict.
		\begin{proof} 
		The proof is not tough. Note that
		\begin{equation*} 
			\int_{\gamma}^{} (M - |f(z)|) {\mathrm{d}}z \ge 0
		\end{equation*}
		since the integrand is nonnegative. Moreover, recall from MA105 that the integral will be zero \textbf{iff} the integrand is identically zero. (We use continuity here.)

		Since we know that the integrand is \emph{not} identically zero, it follows that
		\begin{equation*} 
			\int_{\gamma}^{} (M - |f(z)|) {\mathrm{d}}z > 0.
		\end{equation*}
		Since
		\begin{equation*} 
			\int_{\gamma}^{} M {\mathrm{d}}z = ML,
		\end{equation*}
		the theorem follows.
		\end{proof}

		Now, consider the function
		\begin{equation*} 
			f(z) = \dfrac{z^n}{z^m - 1}
		\end{equation*}
		defined on $\Omega = \{z \in \mathbb{C} : |z| > 1\}.$

		Now, we calculate $M.$ For a point satisfying $|z| = R,$ we note that
		\begin{align*} 
			\left|\dfrac{z^n}{z^m - 1}\right| &= \dfrac{R^n}{|z^m - 1|}\\
			&\le \dfrac{R^n}{||z|^m - 1|}\\
			&= \dfrac{R^n}{R^m - 1}.
		\end{align*}
		Thus, we may take $M = \dfrac{R^n}{R^m - 1}.$ Also, considering $z = R\exp\left(\frac{\iota\pi}{m}\right)$ shows that this inequality is indeed strict at one point. Thus, we may appeal to \nameref{thm:stronkML} to conclude that
		\begin{align*} 
			\left|\int_{|z| = R}^{} \dfrac{z^n}{z^m - 1} {\mathrm{d}}z\right| &\le \int_{|z| = R}^{} \left|\dfrac{z^n}{z^m - 1}\right| {\mathrm{d}}z\\
			&\le M(2\pi R)\\
			&= \dfrac{2\pi R^{n + 1}}{R^{m} - 1}. \qedhere
		\end{align*}
	\end{soln}

	\begin{proof}[Alternate solution]
		The quantity given on the right is strictly positive. (Why?)\\
		Thus, it suffices to show that the integral on the left is $0.$ This is what we shall do.

		Note that the integrand has exactly $m$ distinct (simple) poles. All of these are located on the unit circle. That is, they are all in the interior of the given curve.

		In fact, these poles exactly given by $1, \zeta, \ldots, \zeta^{m-1}$ for $\zeta\vcentcolon=\exp\left(\dfrac{2\pi\iota}{m}\right).$

		Also, note that the denominator can be factorised as
		\begin{equation*} 
			z^m - 1 = (z - 1)(z - \zeta)\cdot\cdots\cdot(z - \zeta^{m-1}).
		\end{equation*}

		For each $0 \le k \le m - 1,$ let $p_k(z)$ denote the product of all the factors on the right excluding $(z - \zeta^k).$ In other words,
		\begin{equation*} 
			p_k(z) \vcentcolon= \prod_{\substack{j = 0\\j\neq k}}^{m-1}(z - \zeta^j).
		\end{equation*}

		With this, we have that
		\begin{equation*} 
			z^m - 1 = (z - \zeta^k)p_k(z)
		\end{equation*}
		for all $0 \le k \le m-1.$ More importantly, the function
		\begin{equation*} 
			\dfrac{z^n}{p_k(z)}
		\end{equation*}
		is well-defined and holomorphic on a small enough neighbourhood of $\zeta^k.$

		Let us now compute $p_k(\zeta^k).$ Note that it must equal
		\begin{equation*} 
			\lim_{z\to \zeta^k}\dfrac{z^m - 1}{z - \zeta^k} = \lim_{z\to \zeta^k}\dfrac{z^m - (\zeta^k)^m}{z - \zeta^k}.
		\end{equation*}
		Interpreting the above as the derivative limit, we get
		\begin{equation*} 
			p_k(\zeta^k) = m\left(\zeta^k\right)^{m-1}.
		\end{equation*}	

		Armed with the above information, we can break up the desired integral as the sum of integrals around each pole and apply Cauchy residue theorem as follows
		\begin{align*} 
			\int_{|z| = R}^{} \dfrac{z^n}{z^m - 1} {\mathrm{d}}z &= \sum_{k=0}^{m-1}\int_{|z-\zeta^k| = \epsilon}^{}\dfrac{z^n}{z^m - 1} {\mathrm{d}}z\\
			&= \sum_{k=0}^{m-1}\int_{|z-\zeta^k| = \epsilon}^{}\dfrac{z^n/p_k(z)}{z - \zeta^k} {\mathrm{d}}z\\
			&= \sum_{k=0}^{m-1}{\color{red}2\pi\iota}\dfrac{\zeta^{nk}}{p_k(\zeta^k)}\\
			&= \dfrac{2\pi\iota}{m}\sum_{k=0}^{m-1}\zeta^{(n-m+1)k}\\
			&= \dfrac{2\pi\iota}{m}\cdot\dfrac{1 - (\zeta^{n-m+1})^m}{1 - \zeta^{n-m+1}}\\
			&= 0. \qedhere
		\end{align*}
	\end{proof}
	%
	%
	%\\
	%
	%
	\item A power series with center at the origin and positive radius of convergence, has a sum $f(z).$ If it is known that $f(\bar{z}) = \overline{f(z)}$ for all values of $z$ within the disc of convergence, what conclusions can you draw about the power series?
	\begin{soln}
		Conclusion: all the coefficients of the power series are real. Let us now justify it.

		Our aim will be to show that $f^{(k)}(0)$ is real for all $k \in \mathbb{N}\cup\{0\}.$ The conclusion will then follow since we know that the coefficients are given by $f^{(k)}(0)/k!.$

		In the following, it will be assumed that $x$ and $x_0$ are real and within the (open) disc of convergence.

		First, we make the conclusion for real $x$ that
		\begin{equation*} 
			f(x) = f(\bar{x}) = \overline{f(x)}.
		\end{equation*}

		That is, $f(x)$ is real whenever $x$ is real. We now wish to show that this is true for all higher derivatives as well. That is, $f^{(k)}(x)$ is real for real $x$ for all $k \ge 1.$ It suffices to show that it is true for $f'.$ \hfill (Why? Induct!)

		Since we know that $f'$ exists within the disc, we may compute the limit along the real axis. Fix a real $x_0$ within the disc and note that
		\begin{equation*} 
			f'(x_0) = \lim_{\substack{x\to x_0\\x\in\mathbb{R}}}\dfrac{f(x) - f(x_0)}{x - x_0}.
		\end{equation*}
		Since the expression within the limit is the quotient of two purely real expressions, we see that the limit $f'(x_0)$ is real.

		Thus, we are done.
	\end{soln}
	\emph{Remark.} Note that we knew that all the higher derivatives of $f$ do exist. Thus, we can reply the inductive process by just computing the limit along the real axis.
	%
	%
	%
	%
	\item This is called Taylor series with remainder:
	\begin{equation*} 
		f(z) = f(0) + zf'(0) + \cdots + \dfrac{z^N}{N!}f^{(N)}(z)(0) + \dfrac{z^{N+1}}{(N + 1)!}\int_{0}^{1} (1 - t)^Nf^{(N+1)}(tz){\mathrm{d}}t
	\end{equation*}
	Use this to prove the following inequalities:
	\begin{enumerate}
		\item $\left|e^z - \displaystyle\sum_{n=0}^{N}\dfrac{z^n}{n!}\right| \le \dfrac{|z|^{N+1}}{(N + 1)!};$ $\Re z \le 0.$
		\item $\left|\cos(z) - \displaystyle\sum_{n=0}^{N}(-1)^n\dfrac{z^{2n}}{(2n)!}\right| \le \dfrac{|z|^{2N+2}\cosh R}{(2N + 2)!};$ $\Im z \le R.$
	\end{enumerate}
	%
	\begin{soln}
		\begin{enumerate}
			\item Note that the sum subtracted is simply the first $N + 1$ terms of the Taylor expansion given. Thus, the quantity given within the modulus is simply
			\begin{equation*} 
				\dfrac{z^{N+1}}{(N + 1)!}\int_{0}^{1} (1 - t)^N\exp(tz){\mathrm{d}}t.
			\end{equation*}
			(We have used that $\exp^{(N+1)} = \exp.$)\\
			Also, note that $\left|\exp(z)\right| = \exp(\Re z).$ \hfill (How?)

			Thus, we get
			\[\begin{WithArrows}[displaystyle]
				\left|\int_{0}^{1} (1 - t)^N\exp(tz){\mathrm{d}}t\right| &\le \int_{0}^{1} \left|(1 - t)^N\exp(tz)\right|{\mathrm{d}}t\\
				&= \int_{0}^{1} (1 - t)^N\exp(t\Re z) {\mathrm{d}}t \Arrow{$\because t\Re z \le 0$}\\
				&\le \int_{0}^{1} (1 - t)^N {\mathrm{d}}t\\
				&= \dfrac{1}{N + 1}
			\end{WithArrows}\]

			Thus, we get the desired result as
			\begin{align*} 
				\left|e^z - \displaystyle\sum_{n=0}^{N}\dfrac{z^n}{n!}\right| &= \left|\dfrac{z^{N+1}}{(N + 1)!}\int_{0}^{1} (1 - t)^N\exp(tz){\mathrm{d}}t\right|\\
				&\le \dfrac{|z|^{N+1}}{(N + 1)!}\dfrac{1}{N + 1}\\
				&\le \dfrac{|z|^{N+1}}{(N + 1)!}.
			\end{align*}
		%
		\item Note that the summation given can be seen as the first $2N + 2$ terms.\\
		(All the coefficients from $z^0$ till $z^{2n+1}$ since we know that the latter is $0.$)

		Thus, the quantity given within the modulus is simply
		\begin{equation*} 
			\dfrac{z^{2N+2}}{(2N + 2)!}\int_{0}^{1} (1 - t)^{2N + 2}\cos^{(2N+2)}(tz){\mathrm{d}}t.
		\end{equation*}

		Note that
		\begin{align*} 
			|\cos(z)| &= \dfrac{1}{2}\left|e^{\iota z} + e^{-\iota z}\right|\\
			&\le\dfrac{1}{2}\left(\left|e^{\iota z}\right| + \left|e^{-\iota z}\right|\right)\\
			&=\dfrac{1}{2}(e^y + e^{-y})\\
			&=\cosh y.
		\end{align*}

		Now, note that $\cos^{(2N+2)}$ is either $\cos$ or $-\cos.$ In either case, we have
		\begin{equation*} 
			\left|\cos^{(2N+2)}(tz)\right| \le \left|\cosh ty\right|.
		\end{equation*}

		Note that $\cosh y$ is an increasing function of $|y|.$ (For real $y$.) Thus, we see that
		\begin{equation*} 
			\left|\cosh ty\right| \le \left|\cosh y\right|
		\end{equation*}
		for all $t \in [0, 1].$

		Moreover, if $|y| \le R,$ we get that
		\begin{equation*} 
			\left|\cosh ty\right| \le \cosh R
		\end{equation*}
		for all $t \in [0, 1].$

		Thus, we get
		\begin{align*} 
			\left|\int_{0}^{1} (1 - t)^{2N + 2}\cos^{(2N+2)}(tz){\mathrm{d}}t\right| &\le \int_{0}^{1} (1 - t)^N\left|\cos^{(2N+2)}(tz)\right|{\mathrm{d}}t\\
			&\le \int_{0}^{1} (1 - t)^{2N + 2} \cosh R {\mathrm{d}}t\\
			&= \dfrac{\cosh R}{2N + 3}.
		\end{align*}
		As earlier, the desired result follows. \qedhere
		\end{enumerate}
	\end{soln}
	%
	%\\
	%
	%
	\item By computing
	\begin{equation*} 
		\int_{|z| = 1}^{} \left(z + \dfrac{1}{z}\right)^{2n}\dfrac{1}{z} {\mathrm{d}}z,
	\end{equation*}
	show that
	\begin{equation*} 
		\int_{0}^{2\pi} \cos^{2n}\theta {\mathrm{d}}\theta = \dfrac{2\pi}{4^n}\cdot\dfrac{(2n)!}{(n!)^2}.
	\end{equation*}
	%
	\begin{soln}
		Recall the ``generalised'' Cauchy integral formula\footnote{My nickname, not standard} which tells us that
		\begin{equation*} 
			\int_{|w - z_0| = r}^{} \dfrac{f(w)}{(w - z_0)^{n+1}} {\mathrm{d}}w = \dfrac{2\pi\iota}{n!}f^{(n)}(z_0)
		\end{equation*}
		where $f$ is a function which is holomorphic on an open disc $D(z_0, R)$ and $r < R.$

		In this question, we take $z_0 = 0,$ $r = 1$ and
		\begin{equation*} 
			f(z) = (z^2 + 1)^{2n}
		\end{equation*}
		which is defined and holomorphic on all of $\mathbb{C}.$

		Using the formula gives us

		\begin{align*} 
			\int_{|z| = 1}^{} \left(z + \dfrac{1}{z}\right)^{2n}\dfrac{1}{z} {\mathrm{d}}z &= \int_{|z| = 1}^{} \dfrac{(z^2 + 1)^{2n}}{z^{2n + 1}} {\mathrm{d}}z\\
			&= \dfrac{2\pi\iota}{(2n)!}f^{(2n)}(0)
		\end{align*}

		Thus, the task is now to compute $f^{(2n)}(0).$ Note that $f^{(2n)}(0)/(2n)!$ is precisely the coefficient of $z^{2n}$ in the expansion of 
		\begin{equation*} 
			(z^2 + 1)^{2n}.
		\end{equation*}

		Use binomial expansion, we see that
		\begin{align*} 
			(z^2 + 1)^{2n} &= \sum_{k=0}^{2n}\dbinom{2n}{k}(z^2)^{k}.
		\end{align*}
		Thus, the desired coefficient is $\dbinom{2n}{n}$ and the integral is
		\begin{equation*} 
			\int_{|z| = 1}^{} \left(z + \dfrac{1}{z}\right)^{2n}\dfrac{1}{z} {\mathrm{d}}z = 2\pi\iota\dbinom{2n}{n}.
		\end{equation*}

		Now, we may compute the integral the menial way, i.e., by \emph{parameterising and solving.}

		Using the standard parameterisation of $z(t) = e^{\iota t}$ for $t \in [0, 2\pi],$ the integral becomes

		\begin{align*} 
			\int_{|z| = 1}^{} \left(z + \dfrac{1}{z}\right)^{2n}\dfrac{1}{z} {\mathrm{d}}z &= \int_{0}^{2\pi} (2\cos t)^{2n}\dfrac{1}{e^{\iota t}}(\iota e^{\iota t}) {\mathrm{d}}t\\
			&= 4^n\iota\int_{0}^{2\pi} \cos^{2n}(t) {\mathrm{d}}t.
		\end{align*}

		Equating it with the previous result gives us the desired answer.
	\end{soln}
	%
	%
	%
	%
	\item Locate and classify the singularities of the following:
	\begin{enumerate}
		\item $\dfrac{z^5\sin(1/z)}{1 + z^4},$
		\item $\dfrac{1}{\sin(1/z)},$
		\item $\dfrac{z^2 + z + 1}{z^3 - 11z + 13}.$
	\end{enumerate}
	%
	\begin{soln}
		In each part, $f(z)$ will denote the function given for that part.
		\begin{enumerate}
			\item To see where the function is not defined, we must see where the argument of some function goes outside the domain.\\
			Fractions are undefined precisely when the denominator is $0.$ Thus, we only need to look at solutions of $z = 0$ and $z^4 + 1 = 0.$

			This gives us $5$ singularities, the complete set being $S = \left\{0, \dfrac{1}{\sqrt{2}}(\pm1\pm\iota)\right\}.$

			All of these are isolated since we have only finitely many singularities. Thus, we may categorise them into one of the following three: removable, pole, or essential singularity.

			Now, if $z_0 \in S\setminus\{0\},$ it is easy to see the following things:
			\begin{enumerate}
				\item $\displaystyle\lim_{z\to z_0}\dfrac{1}{f(z)} = 0,$
				\item $\displaystyle\lim_{z\to z_0}(z - z_0)f(z)$ exists (as a finite number) and is nonzero.
			\end{enumerate}
			Either of these is enough to conclude that $z_0$ is then a pole. Thus, we see that each of the four singularities satisfying $z^4 + 1 = 0$ are poles.

			Finally, we show that $z = 0$ is an \emph{essential} singularity. In other words, we show that it is neither a removable singularity nor a pole. To show that, it suffices to show that $\displaystyle\lim_{z\to 0}f(z)$ does not exist, neither as a finite complex number, nor as $\infty.$

			As we approach $0$ along the positive imaginary axis, we see that
			\begin{align*} 
				\lim_{y\to 0^+}f(z) &= \lim_{y\to 0^+}\dfrac{(\iota y)^5\sin(1/\iota y)}{1 + (\iota y)^5}\\
				&= \dfrac{1}{2}\lim_{y\to 0^+}y^5(e^{1/y} - e^{-1/y})
			\end{align*}
			Since the limit $y^5e^{-1/y}$ exists and $y^5e^{1/y}\to \infty,$ we see that the above limit is $\infty.$ (This shows that $0$ is not a removable singularity.)

			Now, if we approach $0$ along real axis, we know that $\sin$ is bounded and we get the limit as $0$ using the typical sandwich theorem trick from MA 105. Thus, we see that $0$ is not a pole either.
			%
			%
			\item Here, we have a problem if $z = 0$ or $\sin(1/z) = 0.$ This gives us the set of singularities as 
			\begin{equation*} 
				S = \{0\}\cup\left\{\dfrac{1}{n\pi} : n \in \mathbb{Z}\setminus\{0\}\right\}.
			\end{equation*}
			$0$ is not isolated. This is because, every neighbourhood of $0$ contains some point of the form $1/(n\pi).$ In other words, every punctured neighbourhood of $0$ contains a singularity. Thus, $0$ is not an isolated singularity.

			All the other points of $S$ are. To see this, let $z_0 \in S\setminus\{0\}.$ Then, 
			\begin{equation*} 
				z_0 = \dfrac{1}{n\pi}
			\end{equation*}
			for some $n \in \mathbb{Z}\setminus\{0\}.$

			Choose 
			\begin{equation*} 
				\delta \vcentcolon= \min\left\{\left|\dfrac{1}{n\pi} - \dfrac{1}{(n + 1)\pi}\right|, \left|\dfrac{1}{n\pi} - \dfrac{1}{(n - 1)\pi}\right|\right\}.
			\end{equation*}
			(If $n \in \{\pm1\}$, then just choose the other value.)

			Verify that with the above choice of $\delta,$ the punctured neighbourhood $B_\delta(z_0)\setminus\{z_0\}$ contains no other point of $S.$

			Now, we show that all of these isolated singularities are poles. To see this, we simply compute
			\begin{equation*} 
				\lim_{z\to z_0}\dfrac{z - z_0}{\sin(1/z)}
			\end{equation*}
			and see that this limit exists (as a finite number) and is nonzero for any $z_0 \in S\setminus\{0\}.$ (How? Express the above limit as the limit seen in a derivative and compute the derivative using chain rule.) \\
			Thus, they all are poles.

			(Note that we do not try to categorise $0$ since it is not isolated.)
			%
			\item The singularities are precisely the roots of the denominator. These are (at most) $3$ and thus, all are isolated.

			To see that none of these is removable, note that the limit will not exist because none of the roots of the numerator are that of the denominator. (Check that the roots of the numerator are $\omega$ and $\omega^2$ which aren't roots of the denominator).

			We show that these are all poles. Let $z_0$ be a root of the denominator and let $m$ be its multiplicity. Then, note that
			\begin{equation*} 
				\lim_{z\to z_0}(z - z_0)^mf(z)
			\end{equation*}
			exists and is nonzero. (Again, use that $z_0$ is not a root of the numerator.)

			Thus, all the singularities are poles.

			In fact, we can actually check that all the roots are real and distinct. (How? Compute the denominator at $-100,$ $0,$ $2,$ and $100.$) \\
			Thus, $m = 1$ works above for all. \qedhere
		\end{enumerate}
	\end{soln}
\end{enumerate}
\end{document}